{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1be4c178",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "#chargement des données iris\n",
    "iris = datasets.load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.90, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8a8d10e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le score: 0.9185185185185185\n",
      "temps ecoule =0.3674294948577881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wissam/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# réseau de neurone avec 1 couche caché\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import time\n",
    "start_time = time.time()\n",
    "clf = MLPClassifier(hidden_layer_sizes=(50), random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "y_pred = clf.predict(X_test)\n",
    "gain = clf.score(X_test,y_test)\n",
    "print('le score:', gain)\n",
    "print('temps ecoule =' +str(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6b4fcbef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le score: 0.9333333333333333\n",
      "temps ecoule =0.4239482879638672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wissam/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#réseau de neurone pour deux couches\n",
    "start_time = time.time()\n",
    "clf1 = MLPClassifier(hidden_layer_sizes=(50,100), random_state=0)\n",
    "clf1.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "y_pred1 = clf1.predict(X_test)\n",
    "gain1 = clf1.score(X_test,y_test)\n",
    "print('le score:', gain1)\n",
    "print('temps ecoule =' +str(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6c6a6720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le score: 0.9333333333333333\n",
      "temps ecoule =1.313720941543579\n"
     ]
    }
   ],
   "source": [
    "#réseau de neurone pour trois couches\n",
    "start_time = time.time()\n",
    "clf2 = MLPClassifier(hidden_layer_sizes=(50,100,150), random_state=0)\n",
    "clf2.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "y_pred2 = clf2.predict(X_test)\n",
    "gain2 = clf2.score(X_test,y_test)\n",
    "print('le score:', gain2)\n",
    "print('temps ecoule =' +str(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e04b921b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le score: 0.9333333333333333\n",
      "temps ecoule =1.408449411392212\n"
     ]
    }
   ],
   "source": [
    "#réseau de neurone pour quatre couches\n",
    "start_time = time.time()\n",
    "clf3 = MLPClassifier(hidden_layer_sizes=(50,100,150,200), random_state=0)\n",
    "clf3.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "y_pred3 = clf3.predict(X_test)\n",
    "gain3 = clf3.score(X_test,y_test)\n",
    "print('le score:', gain3)\n",
    "print('temps ecoule =' +str(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "09ae518a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le score: 0.9333333333333333\n",
      "temps ecoule =1.8120207786560059\n"
     ]
    }
   ],
   "source": [
    "#réseau de neurone pour cinq couches\n",
    "start_time = time.time()\n",
    "clf4 = MLPClassifier(hidden_layer_sizes=(50,100,150,200,300), random_state=0)\n",
    "clf4.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "y_pred4 = clf4.predict(X_test)\n",
    "gain4 = clf4.score(X_test,y_test)\n",
    "print('le score:', gain4)\n",
    "print('temps ecoule =' +str(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "df7ea99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le score: 0.9407407407407408\n",
      "temps ecoule =0.011321544647216797\n"
     ]
    }
   ],
   "source": [
    "#utiliser classifieur SVM à noyau polynomial\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "start_time = time.time()\n",
    "clsvm = svm.SVC(kernel='poly', C=300)\n",
    "clsvm.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "clsvm.predict(X_test)\n",
    "gains = clsvm.score(X_test,y_test)\n",
    "print('le score:', gains)\n",
    "print('temps ecoule =' +str(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "060096da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalisation des valeurs d'entrées\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9bdf0a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le score: 0.9555555555555556\n",
      "temps ecoule =0.41484904289245605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wissam/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#test avec les nouvelles valeurs normalisées\n",
    "# réseau de neurone avec 1 couche caché\n",
    "start_time = time.time()\n",
    "clf = MLPClassifier(hidden_layer_sizes=(50), random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "y_pred = clf.predict(X_test)\n",
    "gain = clf.score(X_test,y_test)\n",
    "print('le score:', gain)\n",
    "print('temps ecoule =' +str(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aa3e76de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le score: 0.9259259259259259\n",
      "temps ecoule =0.4898793697357178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wissam/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#réseau de neurone pour deux couches\n",
    "start_time = time.time()\n",
    "clf1 = MLPClassifier(hidden_layer_sizes=(50,100), random_state=0)\n",
    "clf1.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "y_pred1 = clf1.predict(X_test)\n",
    "gain1 = clf1.score(X_test,y_test)\n",
    "print('le score:', gain1)\n",
    "print('temps ecoule =' +str(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c5f46186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le score: 0.9481481481481482\n",
      "temps ecoule =0.5989546775817871\n"
     ]
    }
   ],
   "source": [
    "#réseau de neurone pour trois couches\n",
    "start_time = time.time()\n",
    "clf2 = MLPClassifier(hidden_layer_sizes=(50,100,150), random_state=0)\n",
    "clf2.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "y_pred2 = clf2.predict(X_test)\n",
    "gain2 = clf2.score(X_test,y_test)\n",
    "print('le score:', gain2)\n",
    "print('temps ecoule =' +str(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d2561d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le score: 0.9333333333333333\n",
      "temps ecoule =0.36109232902526855\n"
     ]
    }
   ],
   "source": [
    "#réseau de neurone pour quatre couches\n",
    "start_time = time.time()\n",
    "clf3 = MLPClassifier(hidden_layer_sizes=(50,100,150,200), random_state=0)\n",
    "clf3.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "y_pred3 = clf3.predict(X_test)\n",
    "gain3 = clf3.score(X_test,y_test)\n",
    "print('le score:', gain3)\n",
    "print('temps ecoule =' +str(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c2515f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le score: 0.9333333333333333\n",
      "temps ecoule =0.5447947978973389\n"
     ]
    }
   ],
   "source": [
    "#réseau de neurone pour cinq couches\n",
    "start_time = time.time()\n",
    "clf4 = MLPClassifier(hidden_layer_sizes=(50,100,150,200,300), random_state=0)\n",
    "clf4.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "y_pred4 = clf4.predict(X_test)\n",
    "gain4 = clf4.score(X_test,y_test)\n",
    "print('le score:', gain4)\n",
    "print('temps ecoule =' +str(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5ebf967a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le score: 0.9333333333333333\n",
      "temps ecoule =0.014911651611328125\n"
     ]
    }
   ],
   "source": [
    "#utiliser classifieur SVM à noyau polynomial\n",
    "start_time = time.time()\n",
    "clsvm = svm.SVC(kernel='poly', C=300)\n",
    "clsvm.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "clsvm.predict(X_test)\n",
    "gains = clsvm.score(X_test,y_test)\n",
    "print('le score:', gains)\n",
    "print('temps ecoule =' +str(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d4c7ebfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithme optimisation: \u001b[38;5;46m lbfgs \u001b[0m le score: 0.9555555555555556\n",
      "Nbre itérations: 14\n",
      "temps ecoule =0.03194141387939453\n",
      "*********************************\n",
      "Algorithme optimisation: \u001b[38;5;46m sgd \u001b[0m le score: 0.9629629629629629\n",
      "Nbre itérations: 445\n",
      "temps ecoule =0.3946676254272461\n",
      "*********************************\n",
      "Algorithme optimisation: \u001b[38;5;46m adam \u001b[0m le score: 0.9555555555555556\n",
      "Nbre itérations: 117\n",
      "temps ecoule =0.10806083679199219\n",
      "*********************************\n"
     ]
    }
   ],
   "source": [
    "#Étude de la convergence des algorithmes\n",
    "#pour une seule couche\n",
    "\n",
    "liste=['lbfgs','sgd','adam']\n",
    "for i in liste:\n",
    "    start_time = time.time()\n",
    "    clf = MLPClassifier(solver=i, \n",
    "                    hidden_layer_sizes=(50),\n",
    "                    learning_rate_init=0.01,\n",
    "                    max_iter=600,\n",
    "                    random_state=0)\n",
    "    clf.fit(X_train, y_train)\n",
    "    end_time = time.time()\n",
    "    y_pred = clf.predict(X_test)\n",
    "    gain = clf.score(X_test,y_test)\n",
    "    print('Algorithme optimisation:',(\"\\x1b[38;5;46m\"),i,(\"\\x1b[0m\"),'le score:', gain)\n",
    "    print('Nbre itérations:',clf.n_iter_)\n",
    "    print('temps ecoule =' +str(end_time - start_time))\n",
    "    print('*********************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8bfa0eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithme optimisation: \u001b[50;5;46m lbfgs \u001b[0m le score: 0.9333333333333333\n",
      "Nbre itérations: 14\n",
      "temps ecoule =0.11562442779541016\n",
      "*********************************\n",
      "Algorithme optimisation: \u001b[50;5;46m sgd \u001b[0m le score: 0.9555555555555556\n",
      "Nbre itérations: 283\n",
      "temps ecoule =0.4462931156158447\n",
      "*********************************\n",
      "Algorithme optimisation: \u001b[50;5;46m adam \u001b[0m le score: 0.9555555555555556\n",
      "Nbre itérations: 45\n",
      "temps ecoule =0.055736541748046875\n",
      "*********************************\n"
     ]
    }
   ],
   "source": [
    "#Étude de la convergence des algorithmes\n",
    "#pour deux couches\n",
    "\n",
    "liste=['lbfgs','sgd','adam']\n",
    "for i in liste:\n",
    "    start_time = time.time()\n",
    "    clf = MLPClassifier(solver=i, \n",
    "                    hidden_layer_sizes=(50,100),\n",
    "                    learning_rate_init=0.01,\n",
    "                    max_iter=600,\n",
    "                    random_state=0)\n",
    "    clf.fit(X_train, y_train)\n",
    "    end_time = time.time()\n",
    "    y_pred = clf.predict(X_test)\n",
    "    gain = clf.score(X_test,y_test)\n",
    "    print('Algorithme optimisation:',(\"\\x1b[50;5;46m\"),i,(\"\\x1b[0m\"),'le score:', gain)\n",
    "    print('Nbre itérations:',clf.n_iter_)\n",
    "    print('temps ecoule =' +str(end_time - start_time))\n",
    "    print('*********************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e8f0aa80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithme optimisation: \u001b[50;5;46m lbfgs \u001b[0m le score: 0.9333333333333333\n",
      "Nbre itérations: 13\n",
      "temps ecoule =0.4957280158996582\n",
      "*********************************\n",
      "Algorithme optimisation: \u001b[50;5;46m sgd \u001b[0m le score: 0.9481481481481482\n",
      "Nbre itérations: 204\n",
      "temps ecoule =0.47472476959228516\n",
      "*********************************\n",
      "Algorithme optimisation: \u001b[50;5;46m adam \u001b[0m le score: 0.9481481481481482\n",
      "Nbre itérations: 27\n",
      "temps ecoule =0.059278011322021484\n",
      "*********************************\n"
     ]
    }
   ],
   "source": [
    "#Étude de la convergence des algorithmes\n",
    "#pour trois couches\n",
    "\n",
    "liste=['lbfgs','sgd','adam']\n",
    "for i in liste:\n",
    "    start_time = time.time()\n",
    "    clf = MLPClassifier(solver=i, \n",
    "                    hidden_layer_sizes=(50,100,150),\n",
    "                    learning_rate_init=0.01,\n",
    "                    max_iter=600,\n",
    "                    random_state=0)\n",
    "    clf.fit(X_train, y_train)\n",
    "    end_time = time.time()\n",
    "    y_pred = clf.predict(X_test)\n",
    "    gain = clf.score(X_test,y_test)\n",
    "    print('Algorithme optimisation:',(\"\\x1b[50;5;46m\"),i,(\"\\x1b[0m\"),'le score:', gain)\n",
    "    print('Nbre itérations:',clf.n_iter_)\n",
    "    print('temps ecoule =' +str(end_time - start_time))\n",
    "    print('*********************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "02e71aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithme optimisation: \u001b[50;5;46m lbfgs \u001b[0m le score: 0.9481481481481482\n",
      "Nbre itérations: 15\n",
      "temps ecoule =0.3951420783996582\n",
      "*********************************\n",
      "Algorithme optimisation: \u001b[50;5;46m sgd \u001b[0m le score: 0.9407407407407408\n",
      "Nbre itérations: 155\n",
      "temps ecoule =0.6879255771636963\n",
      "*********************************\n",
      "Algorithme optimisation: \u001b[50;5;46m adam \u001b[0m le score: 0.9629629629629629\n",
      "Nbre itérations: 24\n",
      "temps ecoule =0.14946722984313965\n",
      "*********************************\n"
     ]
    }
   ],
   "source": [
    "#Étude de la convergence des algorithmes\n",
    "#pour quatre couches\n",
    "\n",
    "liste=['lbfgs','sgd','adam']\n",
    "for i in liste:\n",
    "    start_time = time.time()\n",
    "    clf = MLPClassifier(solver=i, \n",
    "                    hidden_layer_sizes=(50,100,150,200),\n",
    "                    learning_rate_init=0.01,\n",
    "                    max_iter=600,\n",
    "                    random_state=0)\n",
    "    clf.fit(X_train, y_train)\n",
    "    end_time = time.time()\n",
    "    y_pred = clf.predict(X_test)\n",
    "    gain = clf.score(X_test,y_test)\n",
    "    print('Algorithme optimisation:',(\"\\x1b[50;5;46m\"),i,(\"\\x1b[0m\"),'le score:', gain)\n",
    "    print('Nbre itérations:',clf.n_iter_)\n",
    "    print('temps ecoule =' +str(end_time - start_time))\n",
    "    print('*********************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "70fadb10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithme optimisation: \u001b[50;5;46m lbfgs \u001b[0m le score: 0.9333333333333333\n",
      "Nbre itérations: 26\n",
      "temps ecoule =2.0503835678100586\n",
      "*********************************\n",
      "Algorithme optimisation: \u001b[50;5;46m sgd \u001b[0m le score: 0.9555555555555556\n",
      "Nbre itérations: 144\n",
      "temps ecoule =1.2348761558532715\n",
      "*********************************\n",
      "Algorithme optimisation: \u001b[50;5;46m adam \u001b[0m le score: 0.9333333333333333\n",
      "Nbre itérations: 27\n",
      "temps ecoule =0.26810407638549805\n",
      "*********************************\n"
     ]
    }
   ],
   "source": [
    "#Étude de la convergence des algorithmes\n",
    "#pour cinq couches\n",
    "\n",
    "liste=['lbfgs','sgd','adam']\n",
    "for i in liste:\n",
    "    start_time = time.time()\n",
    "    clf = MLPClassifier(solver=i, \n",
    "                    hidden_layer_sizes=(50,100,150,200,300),\n",
    "                    learning_rate_init=0.01,\n",
    "                    max_iter=600,\n",
    "                    random_state=0)\n",
    "    clf.fit(X_train, y_train)\n",
    "    end_time = time.time()\n",
    "    y_pred = clf.predict(X_test)\n",
    "    gain = clf.score(X_test,y_test)\n",
    "    print('Algorithme optimisation:',(\"\\x1b[50;5;46m\"),i,(\"\\x1b[0m\"),'le score:', gain)\n",
    "    print('Nbre itérations:',clf.n_iter_)\n",
    "    print('temps ecoule =' +str(end_time - start_time))\n",
    "    print('*********************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "db386e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valeur alpha: \u001b[38;5;46m 0.0001 \u001b[0m le score: 0.9555555555555556\n",
      "Nbre itérations: 14\n",
      "temps ecoule =0.019884109497070312\n",
      "*********************************\n",
      "valeur alpha: \u001b[38;5;46m 0.001 \u001b[0m le score: 0.9555555555555556\n",
      "Nbre itérations: 28\n",
      "temps ecoule =0.02364635467529297\n",
      "*********************************\n",
      "valeur alpha: \u001b[38;5;46m 0.005 \u001b[0m le score: 0.9555555555555556\n",
      "Nbre itérations: 75\n",
      "temps ecoule =0.07314634323120117\n",
      "*********************************\n",
      "valeur alpha: \u001b[38;5;46m 0.01 \u001b[0m le score: 0.9555555555555556\n",
      "Nbre itérations: 226\n",
      "temps ecoule =0.20676088333129883\n",
      "*********************************\n",
      "valeur alpha: \u001b[38;5;46m 0.1 \u001b[0m le score: 0.9555555555555556\n",
      "Nbre itérations: 287\n",
      "temps ecoule =0.22211885452270508\n",
      "*********************************\n",
      "valeur alpha: \u001b[38;5;46m 0.8 \u001b[0m le score: 0.9407407407407408\n",
      "Nbre itérations: 184\n",
      "temps ecoule =0.12593388557434082\n",
      "*********************************\n"
     ]
    }
   ],
   "source": [
    "#améliorer les résultats en faisant varier la magnitude de la régularisation alpha\n",
    "val_alpha=[0.0001, 0.001, 0.005,0.01, 0.1, 0.8 ]\n",
    "for i in val_alpha:\n",
    "    start_time = time.time()\n",
    "    clf = MLPClassifier(solver='lbfgs', \n",
    "                    hidden_layer_sizes=(50),\n",
    "                    alpha=i,\n",
    "                    learning_rate_init=0.01,\n",
    "                    max_iter=600,\n",
    "                    random_state=0)\n",
    "    clf.fit(X_train, y_train)\n",
    "    end_time = time.time()\n",
    "    y_pred = clf.predict(X_test)\n",
    "    gain = clf.score(X_test,y_test)\n",
    "    print('valeur alpha:',(\"\\x1b[38;5;46m\"),i,(\"\\x1b[0m\"),'le score:', gain)\n",
    "    print('Nbre itérations:',clf.n_iter_)\n",
    "    print('temps ecoule =' +str(end_time - start_time))\n",
    "    print('*********************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "42eda15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wissam/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/wissam/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/wissam/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/wissam/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/wissam/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/wissam/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/wissam/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/wissam/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/wissam/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/wissam/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/wissam/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/wissam/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/wissam/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/wissam/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/wissam/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/wissam/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "les valeurs de paramètres optimales sont:\n",
      " {'alpha': 1e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wissam/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#recherche des paramètres optimaux\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#création des paramétres\n",
    "para= {'alpha':[0.00001,0.00009 ,0.0001, 0.001, 0.005,0.01, 0.1, 0.8  ]}\n",
    "mod= GridSearchCV(MLPClassifier(), para, cv=2)\n",
    "\n",
    "mod.fit(X_train, y_train)\n",
    "\n",
    "print(\"les valeurs de paramètres optimales sont:\\n\",mod.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1654612",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02ceb3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba8491a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b6a3a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf427f1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83238821",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
